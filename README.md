# Atendimento por Voz com IA

Sistema de atendimento por voz que utiliza IA para responder perguntas em tempo real, desenvolvido seguindo os princÃ­pios de Clean Architecture e Clean Code.

## ğŸš€ Funcionalidades

- ğŸ™ï¸ Reconhecimento de voz em portuguÃªs
- ğŸ¤– Respostas em tempo real usando a API da OpenAI (GPT-3.5-turbo)
- ğŸ’¬ Interface de linha de comando interativa
- ğŸ“œ HistÃ³rico de conversa
- âš™ï¸ ConfiguraÃ§Ãµes personalizÃ¡veis
- ğŸ› ï¸ Arquitetura limpa e modular
- ğŸ§ª Pronto para testes

## ğŸ“‹ PrÃ©-requisitos

- Python 3.8 ou superior
- Microfone funcional
- Alto-falantes
- Conta na OpenAI (para obter uma chave de API)
- Git (opcional, apenas para clonar o repositÃ³rio)

## ğŸ› ï¸ InstalaÃ§Ã£o

1. Clone o repositÃ³rio (ou baixe o cÃ³digo fonte):
   ```bash
   git clone https://github.com/seu-usuario/atendimento-ia-poc.git
   cd atendimento-ia-poc
   ```

2. Crie e ative um ambiente virtual (recomendado):
   ```bash
   # Windows
   python -m venv venv
   .\venv\Scripts\activate
   
   # Linux/MacOS
   python3 -m venv venv
   source venv/bin/activate
   ```

3. Instale as dependÃªncias:
   ```bash
   pip install -r requirements.txt
   ```

4. Crie um arquivo `.env` na raiz do projeto com as seguintes variÃ¡veis:
   ```env
   # Chave da API da OpenAI (obrigatÃ³ria)
   OPENAI_API_KEY=sua_chave_aqui
   
   # ConfiguraÃ§Ãµes opcionais (valores padrÃ£o mostrados)
   OPENAI_MODEL=gpt-3.5-turbo
   OPENAI_MAX_TOKENS=150
   OPENAI_TEMPERATURE=0.7
   
   # ConfiguraÃ§Ãµes de voz
   VOICE_RATE=150
   VOICE_VOLUME=0.9
   VOICE_LANGUAGE=pt-BR
   
   # ConfiguraÃ§Ãµes de reconhecimento de fala
   SPEECH_ENERGY_THRESHOLD=300
   SPEECH_PAUSE_THRESHOLD=0.8
   
   # ConfiguraÃ§Ãµes da aplicaÃ§Ã£o
   APP_NAME=Atendimento IA
   APP_VERSION=0.1.0
   DEBUG=False
   ```

## ğŸš€ Como Usar

1. Inicie o aplicativo:
   ```bash
   python main.py
   ```

2. Comandos disponÃ­veis:
   - `fale`: Iniciar o modo de fala
   - `texto`: Digitar uma mensagem
   - `historico`: Ver histÃ³rico da conversa
   - `limpar`: Limpar o histÃ³rico da conversa
   - `ajuda`: Mostrar ajuda
   - `sair`: Encerrar o atendimento

3. Fale claramente quando solicitado ou digite sua mensagem.

## ğŸ—ï¸ Estrutura do Projeto

```
src/
â”œâ”€â”€ domain/                  # LÃ³gica de domÃ­nio
â”‚   â”œâ”€â”€ entities/            # Entidades de domÃ­nio
â”‚   â””â”€â”€ use_cases/           # Casos de uso
â”œâ”€â”€ infrastructure/          # ImplementaÃ§Ãµes concretas
â”‚   â”œâ”€â”€ adapters/            # Adaptadores para serviÃ§os externos
â”‚   â””â”€â”€ config/              # ConfiguraÃ§Ãµes
â””â”€â”€ interface/               # Interfaces de usuÃ¡rio
    â””â”€â”€ cli/                 # Interface de linha de comando

tests/                      # Testes automatizados
â”œâ”€â”€ unit/                   # Testes unitÃ¡rios
â””â”€â”€ integration/            # Testes de integraÃ§Ã£o
```

## ğŸ§ª Testes

Para executar os testes:

```bash
# Instalar dependÃªncias de desenvolvimento
pip install -r requirements-dev.txt

# Executar testes
pytest
```

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a licenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues e enviar pull requests.

## ğŸ“ Suporte

Para suporte, por favor abra uma issue no repositÃ³rio.

---

Desenvolvido com â¤ï¸ por [Seu Nome]

## âœ… **Status: Ollama jÃ¡ estÃ¡ rodando!**

### **1. Verificar se estÃ¡ funcionando:**
```powershell
ollama list
```

### **2. Baixar o modelo (em outro terminal):**
```powershell
ollama pull llama2
```

### **3. Testar o modelo:**
```powershell
ollama run llama2 "OlÃ¡, como vocÃª estÃ¡?"
```

## ğŸš€ **Agora vamos implementar o adaptador Ollama no sistema:**

### **1. Primeiro, vamos criar o adaptador Ollama:**
