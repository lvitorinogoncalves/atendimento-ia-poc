# Atendimento por Voz com IA

Sistema de atendimento por voz que utiliza **mÃºltiplos modelos de IA** para responder perguntas em tempo real, desenvolvido seguindo os princÃ­pios de **Clean Architecture** e **Clean Code**.

## ğŸš€ Funcionalidades

* ğŸ™ï¸ **Reconhecimento de voz em portuguÃªs**
* ğŸ¤– **IntegraÃ§Ã£o Multi-Model AI**

  * **OpenAI GPT-3.5-turbo** (primÃ¡rio)
  * **DeepSeek** (fallback secundÃ¡rio)
  * **Ollama** (modelos locais como backup final)
* ğŸ”„ **Fallback inteligente com failover transparente**

  * DetecÃ§Ã£o automÃ¡tica de erros de *quota* e *rate limiting*
  * AlternÃ¢ncia automÃ¡tica entre modelos sem interromper o atendimento
* ğŸ’¬ Interface de **linha de comando interativa**
* ğŸ“œ **HistÃ³rico de conversas** para manter contexto
* âš™ï¸ **ConfiguraÃ§Ãµes flexÃ­veis** via `.env`
* ğŸ› ï¸ **Arquitetura limpa, modular e resiliente**
* ğŸ§ª Suporte a **testes automatizados** com `pytest`

## ğŸ“‹ PrÃ©-requisitos

* Python 3.8 ou superior
* Microfone e alto-falantes
* Conta na **OpenAI** (obrigatÃ³ria)
* Conta na **DeepSeek** (opcional, usada no fallback)
* **Ollama** instalado para uso de modelos locais
* Git (opcional, apenas para clonar o repositÃ³rio)

## ğŸ› ï¸ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:

   ```bash
   git clone https://github.com/seu-usuario/atendimento-ia-poc.git
   cd atendimento-ia-poc
   ```

2. Crie e ative um ambiente virtual:

   ```bash
   # Windows
   python -m venv venv
   .\venv\Scripts\activate

   # Linux/MacOS
   python3 -m venv venv
   source venv/bin/activate
   ```

3. Instale as dependÃªncias:

   ```bash
   pip install -r requirements.txt
   ```

4. Crie um arquivo `.env` na raiz do projeto com as seguintes variÃ¡veis:

   ```env
   # OpenAI (obrigatÃ³rio)
   OPENAI_API_KEY=sua_chave_aqui
   OPENAI_MODEL=gpt-3.5-turbo
   OPENAI_MAX_TOKENS=150
   OPENAI_TEMPERATURE=0.7

   # DeepSeek (opcional, usado no fallback)
   DEEPSEEK_API_KEY=sua_chave_aqui

   # ConfiguraÃ§Ãµes de voz
   VOICE_RATE=150
   VOICE_VOLUME=0.9
   VOICE_LANGUAGE=pt-BR

   # Reconhecimento de fala
   SPEECH_ENERGY_THRESHOLD=300
   SPEECH_PAUSE_THRESHOLD=0.8

   # ConfiguraÃ§Ãµes gerais
   APP_NAME=Atendimento IA
   APP_VERSION=0.1.0
   DEBUG=False
   ```

## ğŸš€ Como Usar

1. Inicie o aplicativo:

   ```bash
   python main.py
   ```

2. Comandos disponÃ­veis:

   * `fale`: Iniciar o modo de fala
   * `texto`: Digitar uma mensagem
   * `historico`: Ver histÃ³rico da conversa
   * `limpar`: Limpar o histÃ³rico da conversa
   * `ajuda`: Mostrar ajuda
   * `sair`: Encerrar o atendimento

3. Fale claramente quando solicitado ou digite sua mensagem.

## ğŸ—ï¸ Estrutura do Projeto

```
src/
â”œâ”€â”€ domain/                  # LÃ³gica de domÃ­nio
â”‚   â”œâ”€â”€ entities/            # Entidades de domÃ­nio
â”‚   â””â”€â”€ use_cases/           # Casos de uso
â”œâ”€â”€ infrastructure/          # ImplementaÃ§Ãµes concretas
â”‚   â”œâ”€â”€ adapters/            # Adaptadores para serviÃ§os externos (OpenAI, DeepSeek, Ollama)
â”‚   â””â”€â”€ config/              # ConfiguraÃ§Ãµes
â””â”€â”€ interface/               # Interfaces de usuÃ¡rio
    â””â”€â”€ cli/                 # Interface de linha de comando

tests/                      # Testes automatizados
â”œâ”€â”€ unit/                   # Testes unitÃ¡rios
â””â”€â”€ integration/            # Testes de integraÃ§Ã£o
```

## âœ… Suporte ao Ollama

Este projeto jÃ¡ conta com integraÃ§Ã£o ao **Ollama** como Ãºltima camada de fallback.

### Testando o Ollama:

```powershell
ollama list
ollama pull llama2
ollama run llama2 "OlÃ¡, como vocÃª estÃ¡?"
```

---

## ğŸ§ª Testes

Para executar os testes:

```bash
# Instalar dependÃªncias de desenvolvimento
pip install -r requirements-dev.txt

# Executar testes
pytest
```

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a licenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Abra uma issue ou envie um pull request.

## ğŸ“ Suporte

Para suporte, por favor abra uma issue no repositÃ³rio.
